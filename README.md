# AI DevOps Platform

A cloud-native, AI-powered monitoring platform designed to help DevOps teams proactively identify anomalies, predict issues, and optimize their infrastructure using machine learning.

## Overview

This platform consists of two main components:

*   **`central-brain`**: A serverless AWS Lambda function that serves as the AI/ML core. It ingests data via an API Gateway endpoint, stores it in DynamoDB, and sends alerts.
*   **`edge-agent`**: A lightweight, containerized agent that is deployed to your infrastructure to collect and forward Prometheus metrics. (Note: Its direct role is being de-emphasized in favor of more standard data ingestion methods).

The entire infrastructure is managed via Terraform, and CI/CD pipelines are set up using GitHub Actions to automatically build and deploy the components.

## Architecture

*   **Data Ingestion**: A secure API Gateway endpoint receives monitoring data (e.g., metrics, events) in JSON format.
*   **Processing & Storage**: The `central-brain` Lambda function processes the incoming JSON data, transforms it, and stores the resulting metric samples in a DynamoDB table for persistence and future analysis.
*   **Alerting**: If an anomaly is detected (functionality temporarily disabled), the `central-brain` sends an alert via Telegram.
*   **Infrastructure**: All backend components (API Gateway, Lambda, DynamoDB, S3, IAM) are provisioned on AWS using Terraform.

## Getting Started

### Prerequisites

*   An AWS Account
*   Terraform installed
*   Docker installed
*   A Telegram Bot Token and Chat ID for alerts

### 1. Infrastructure Deployment

The core infrastructure is managed by Terraform.

1.  **Configure AWS Credentials**: Ensure your environment is configured with AWS credentials that have permissions to create the required resources.
2.  **Initialize Terraform**:
    ```bash
    ./scripts/terraform-init.sh
    ```
3.  **Deploy**:
    ```bash
    cd infrastructure/terraform
    terraform apply
    ```

### 2. Component Deployment

*   **`central-brain`**: This component is automatically built and deployed by the GitHub Actions workflow (`.github/workflows/central-brain.yaml`) whenever changes are pushed to the `main` branch. The workflow packages the Python code and deploys it to the AWS Lambda function created by Terraform.

*   **`edge-agent`**: The agent is designed to be run as a Docker container on the server you want to monitor. See the [Edge Agent README](edge-agent/README.md) for detailed deployment instructions.

## Usage

Once the infrastructure is up and the `edge-agent` is deployed, metrics will be collected every 5 minutes. The `central-brain` will analyze this data and send a Telegram message if the `up` metric for any monitored job is `0`.

## Future Work

*   Refine and expand the anomaly detection models.
*   Add more alerting channels (Email, Slack, PagerDuty).
*   Develop a web-based UI for visualizing metrics and anomalies.

---
*This README was generated by Gemini.*