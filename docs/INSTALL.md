## Installation Guide

This guide provides detailed steps for deploying the AI DevOps Platform.

### Prerequisites

*   **AWS Account**: You will need an AWS account with permissions to create IAM roles, S3 buckets, DynamoDB tables, Lambda functions, and Lambda Function URLs.
*   **Terraform**: [Install Terraform](https://learn.hashicorp.com/tutorials/terraform/install-cli) (v1.0.0 or newer).
*   **Docker**: [Install Docker](https://docs.docker.com/get-docker/) to build and run the OpenTelemetry Collector.
*   **Python**: Python 3.9+ is required for local testing and utility scripts.
*   **Telegram Bot**:
    *   Create a Telegram bot by talking to the [BotFather](https://t.me/botfather).
    *   Note down the **Bot Token**.
    *   Create a new channel or group for alerts.
    *   Add your bot to the channel/group as an administrator.
    *   Find your **Chat ID**. You can get this by sending a message to your channel and then visiting `https://api.telegram.org/bot<YourBOTToken>/getUpdates`.

### Step 1: Configure Environment

Clone the repository and set up your environment variables.

1.  **Clone the repository**:
    ```bash
    git clone https://github.com/your-username/ai-devops-platform.git
    cd ai-devops-platform
    ```

2.  **Set up AWS Credentials**:
    Configure your AWS credentials so that Terraform and other scripts can access your account. The recommended way is to set the following environment variables:
    ```bash
    export AWS_ACCESS_KEY_ID="YOUR_AWS_ACCESS_KEY"
    export AWS_SECRET_ACCESS_KEY="YOUR_AWS_SECRET_KEY"
    export AWS_REGION="us-east-1"
    ```

### Step 2: Deploy Backend Infrastructure

The backend infrastructure is managed with Terraform.

1.  **Navigate to the Terraform directory**:
    ```bash
    cd infrastructure/terraform
    ```

2.  **Initialize Terraform**:
    This will download the necessary providers and modules.
    ```bash
    terraform init
    ```
    *Note*: The Terraform state is stored remotely in an S3 bucket, which is created on the first run.

3.  **Apply the Terraform configuration**:
    This command will provision all the necessary AWS resources (Lambda, DynamoDB, Lambda Function URL, etc.).
    ```bash
    terraform apply
    ```
    Review the plan and type `yes` to approve it. After successful deployment, Terraform will output the `lambda_function_url`. Copy this URL.

### Step 3: Central Brain Deployment

The `central-brain` service is deployed automatically via a GitHub Actions CI/CD pipeline. When you push a commit to the `main` branch, the workflow will:
1.  Package the Python application code into a zip file.
2.  Upload the zip file to the AWS Lambda function.

To trigger the first deployment, you can simply make a small commit and push it:
```bash
git commit --allow-empty -m "Trigger initial deployment"
git push origin main
```

### Step 4: OpenTelemetry Collector Setup

1.  **Update Collector Configuration**: Copy the `otel-collector-config.yaml` file from this repository to your collector's server. Update the `endpoint` in this file to the `lambda_function_url` obtained from Terraform deployment.
2.  **Run Collector**: Start the OpenTelemetry Collector using Docker. Ensure you mount your log directories and pass your API key.
    ```bash
    docker run -d --rm \
      -v $(pwd)/otel-collector-config.yaml:/etc/otel-collector-config.yaml \
      -v /var/log:/var/log/ # Mount your log directory here (e.g., /home/user/app_logs:/var/log/)\
      -e API_KEY="your_api_key_here" \
      otel/opentelemetry-collector-contrib:latest \
      --config /etc/otel-collector-config.yaml
    ```

---
*This document was generated by Gemini.*